
<!doctype html>
<html lang="fr" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://blog.neutron-it.fr/OpenShift/Intelligence-Artificielle/CVAT-YOLO/">
      
      
        <link rel="prev" href="../../Configuration/openshift-image-registry/">
      
      
        <link rel="next" href="../DeepSeek/">
      
      
      <link rel="icon" href="../../../assets/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.21">
    
    
      
        <title>De l'Annotation à la Détection : Entraîner un Modèle YOLO sur OpenShift AI - </title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2a3383ac.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="neutron-it" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction" class="md-skip">
          Aller au contenu
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="En-tête">
    <a href="../../.." title="" class="md-header__button md-logo" aria-label="" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              De l'Annotation à la Détection : Entraîner un Modèle YOLO sur OpenShift AI
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Rechercher" placeholder="Rechercher" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Recherche">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Partager" aria-label="Partager" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Effacer" aria-label="Effacer" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initialisation de la recherche
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="" class="md-nav__button md-logo" aria-label="" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Accueil
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tags/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tous les articles
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    BootC
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            BootC
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../BootC/MinIO/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Déployer MinIO avec BootC
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    OpenShift
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            OpenShift
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Configuration
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Configuration
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Configuration/openshift-image-registry/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comment exposer la registry interne OpenShift ?
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" checked>
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Intelligence Artificielle
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Intelligence Artificielle
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    De l'Annotation à la Détection : Entraîner un Modèle YOLO sur OpenShift AI
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    De l'Annotation à la Détection : Entraîner un Modèle YOLO sur OpenShift AI
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table des matières">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table des matières
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code-source" class="md-nav__link">
    <span class="md-ellipsis">
      Code Source
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-recuperation-du-jeu-de-donnees-via-git" class="md-nav__link">
    <span class="md-ellipsis">
      1. Récupération du Jeu de Données via Git
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-deploiement-et-configuration-de-cvat" class="md-nav__link">
    <span class="md-ellipsis">
      2. Déploiement et Configuration de CVAT
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Déploiement et Configuration de CVAT">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-deploiement-de-cvat-sur-openshift" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Déploiement de CVAT sur OpenShift
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-creation-dune-organisation" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Création d'une Organisation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-creation-du-projet-dannotation-sur-cvat" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Création du Projet d'Annotation sur CVAT
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-creation-dune-tache-dannotation" class="md-nav__link">
    <span class="md-ellipsis">
      3. Création d'une Tâche d'Annotation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-lancement-de-lannotation" class="md-nav__link">
    <span class="md-ellipsis">
      4. Lancement de l'Annotation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Lancement de l&#39;Annotation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linterface-dannotation" class="md-nav__link">
    <span class="md-ellipsis">
      L'Interface d'Annotation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-exporter-les-annotations-au-format-yolo" class="md-nav__link">
    <span class="md-ellipsis">
      5. Exporter les Annotations au Format YOLO
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-preparation-et-centralisation-du-dataset-sur-minio" class="md-nav__link">
    <span class="md-ellipsis">
      6. Préparation et Centralisation du Dataset sur MinIO
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-importation-du-dataset-pour-lentrainement" class="md-nav__link">
    <span class="md-ellipsis">
      7. Importation du Dataset pour l'Entraînement
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Importation du Dataset pour l&#39;Entraînement">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-configuration-via-linterface-dopenshift-ai" class="md-nav__link">
    <span class="md-ellipsis">
      7.1. Configuration via l'Interface d'OpenShift AI
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-configuration-et-connexion" class="md-nav__link">
    <span class="md-ellipsis">
      7.2. Configuration et Connexion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-telechargement-et-restructuration" class="md-nav__link">
    <span class="md-ellipsis">
      7.3. Téléchargement et Restructuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-creation-du-fichier-datayaml" class="md-nav__link">
    <span class="md-ellipsis">
      7.4. Création du Fichier data.yaml
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75-execution" class="md-nav__link">
    <span class="md-ellipsis">
      7.5. Exécution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-entrainement-du-modele-avec-yolo" class="md-nav__link">
    <span class="md-ellipsis">
      8. Entraînement du Modèle avec YOLO
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Entraînement du Modèle avec YOLO">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-preparation-du-modele-de-base-yolo" class="md-nav__link">
    <span class="md-ellipsis">
      8.1. Préparation du Modèle de Base YOLO
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-installation-et-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      8.2. Installation et Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-chargement-du-modele-de-base" class="md-nav__link">
    <span class="md-ellipsis">
      8.3. Chargement du Modèle de Base
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-lancement-de-lentrainement" class="md-nav__link">
    <span class="md-ellipsis">
      8.4. Lancement de l'Entraînement
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85-exportation-et-sauvegarde-des-resultats" class="md-nav__link">
    <span class="md-ellipsis">
      8.5. Exportation et Sauvegarde des Résultats
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-comparaison-et-validation-des-resultats" class="md-nav__link">
    <span class="md-ellipsis">
      9. Comparaison et Validation des Résultats
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Comparaison et Validation des Résultats">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-comparaison-quantitative-mesurer-la-performance" class="md-nav__link">
    <span class="md-ellipsis">
      9.1. Comparaison Quantitative : Mesurer la Performance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-comparaison-qualitative-visualiser-la-detection" class="md-nav__link">
    <span class="md-ellipsis">
      9.2. Comparaison Qualitative : Visualiser la Détection
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion-generale" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion Générale
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DeepSeek/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Déploiement de DeepSeek sur OpenShift
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../EdgeIA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L'Edge IA dans l'écosystème RedHat
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ObjectDetection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Entraînement et évaluation d'un modèle YOLO
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../SharedGPU/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Configuration de GPU sur OpenShift
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llamaCPP/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Déploiement de modèle en inférence sur OpenShift
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rag_llama_minio_blog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mise en place d'un RAG déconnecté sur OpenShift AI
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Operator
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            Operator
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Operator/Vaultwarden/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Création d'un Operator sur OpenShift avec Vaultwarden
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    RealTime
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            RealTime
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../RealTime/RealTime/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Utiliser les capacités temps réel d'OpenShift
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table des matières">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table des matières
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code-source" class="md-nav__link">
    <span class="md-ellipsis">
      Code Source
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-recuperation-du-jeu-de-donnees-via-git" class="md-nav__link">
    <span class="md-ellipsis">
      1. Récupération du Jeu de Données via Git
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-deploiement-et-configuration-de-cvat" class="md-nav__link">
    <span class="md-ellipsis">
      2. Déploiement et Configuration de CVAT
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Déploiement et Configuration de CVAT">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-deploiement-de-cvat-sur-openshift" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Déploiement de CVAT sur OpenShift
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-creation-dune-organisation" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Création d'une Organisation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-creation-du-projet-dannotation-sur-cvat" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Création du Projet d'Annotation sur CVAT
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-creation-dune-tache-dannotation" class="md-nav__link">
    <span class="md-ellipsis">
      3. Création d'une Tâche d'Annotation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-lancement-de-lannotation" class="md-nav__link">
    <span class="md-ellipsis">
      4. Lancement de l'Annotation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Lancement de l&#39;Annotation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linterface-dannotation" class="md-nav__link">
    <span class="md-ellipsis">
      L'Interface d'Annotation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-exporter-les-annotations-au-format-yolo" class="md-nav__link">
    <span class="md-ellipsis">
      5. Exporter les Annotations au Format YOLO
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-preparation-et-centralisation-du-dataset-sur-minio" class="md-nav__link">
    <span class="md-ellipsis">
      6. Préparation et Centralisation du Dataset sur MinIO
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-importation-du-dataset-pour-lentrainement" class="md-nav__link">
    <span class="md-ellipsis">
      7. Importation du Dataset pour l'Entraînement
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Importation du Dataset pour l&#39;Entraînement">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-configuration-via-linterface-dopenshift-ai" class="md-nav__link">
    <span class="md-ellipsis">
      7.1. Configuration via l'Interface d'OpenShift AI
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-configuration-et-connexion" class="md-nav__link">
    <span class="md-ellipsis">
      7.2. Configuration et Connexion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-telechargement-et-restructuration" class="md-nav__link">
    <span class="md-ellipsis">
      7.3. Téléchargement et Restructuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-creation-du-fichier-datayaml" class="md-nav__link">
    <span class="md-ellipsis">
      7.4. Création du Fichier data.yaml
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75-execution" class="md-nav__link">
    <span class="md-ellipsis">
      7.5. Exécution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-entrainement-du-modele-avec-yolo" class="md-nav__link">
    <span class="md-ellipsis">
      8. Entraînement du Modèle avec YOLO
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Entraînement du Modèle avec YOLO">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-preparation-du-modele-de-base-yolo" class="md-nav__link">
    <span class="md-ellipsis">
      8.1. Préparation du Modèle de Base YOLO
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-installation-et-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      8.2. Installation et Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-chargement-du-modele-de-base" class="md-nav__link">
    <span class="md-ellipsis">
      8.3. Chargement du Modèle de Base
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-lancement-de-lentrainement" class="md-nav__link">
    <span class="md-ellipsis">
      8.4. Lancement de l'Entraînement
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85-exportation-et-sauvegarde-des-resultats" class="md-nav__link">
    <span class="md-ellipsis">
      8.5. Exportation et Sauvegarde des Résultats
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-comparaison-et-validation-des-resultats" class="md-nav__link">
    <span class="md-ellipsis">
      9. Comparaison et Validation des Résultats
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Comparaison et Validation des Résultats">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-comparaison-quantitative-mesurer-la-performance" class="md-nav__link">
    <span class="md-ellipsis">
      9.1. Comparaison Quantitative : Mesurer la Performance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-comparaison-qualitative-visualiser-la-detection" class="md-nav__link">
    <span class="md-ellipsis">
      9.2. Comparaison Qualitative : Visualiser la Détection
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion-generale" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion Générale
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <nav class="md-tags" >
    
      
      
      
        <a href="../../../tags/#tag:cvat" class="md-tag">CVAT</a>
      
    
      
      
      
        <a href="../../../tags/#tag:computer-vision" class="md-tag">Computer Vision</a>
      
    
      
      
      
        <a href="../../../tags/#tag:ia" class="md-tag">IA</a>
      
    
      
      
      
        <a href="../../../tags/#tag:machine-learning" class="md-tag">Machine Learning</a>
      
    
      
      
      
        <a href="../../../tags/#tag:object-detection" class="md-tag">Object Detection</a>
      
    
      
      
      
        <a href="../../../tags/#tag:openshift" class="md-tag">OpenShift</a>
      
    
      
      
      
        <a href="../../../tags/#tag:yolo" class="md-tag">YOLO</a>
      
    
  </nav>



<h1 id="de-lannotation-a-la-detection-entrainer-un-modele-yolo-sur-openshift-ai">De l'Annotation à la Détection : Entraîner un Modèle YOLO sur OpenShift AI</h1>
<p><img alt="Comparaison de détection sur un Concorde" class="scaled-image" src="../img/Capture_Resultat_YOLO.png" /> </p>
<h2 id="introduction">Introduction</h2>
<p>Dans le domaine de la vision par ordinateur, la performance d'un modèle de détection d'objets dépend massivement de la qualité de son jeu de données d'entraînement. Un bon modèle nécessite des milliers d'exemples correctement annotés, une tâche qui peut rapidement devenir complexe et fastidieuse. C'est ici qu'interviennent des outils spécialisés comme <strong>CVAT</strong> et des modèles de pointe comme <strong>YOLO</strong>.</p>
<p><strong>CVAT (Computer Vision Annotation Tool)</strong> est une plateforme open-source puissante, conçue pour simplifier et accélérer l'annotation d'images et de vidéos. De son côté, YOLO (You Only Look Once) est l'un des modèles de détection d'objets en temps réel les plus populaires et performants.</p>
<p>Cet article vous guidera pas à pas à travers le processus complet : de l'annotation d'un jeu de données personnalisé avec CVAT à l'exportation des annotations au format YOLO, pour finalement entraîner notre propre modèle de détection d'objets.</p>
<hr />
<h2 id="code-source">Code Source</h2>
<p>Le dépôt GitHub ci-dessous contient tous les notebooks, scripts et fichiers de configuration nécessaires pour suivre ce tutoriel et entraîner votre propre modèle YOLO.</p>
<p><strong><a href="https://github.com/neutron-IT-organization/CVAT-YOLO-Training.git">Accéder au projet sur GitHub</a></strong></p>
<h2 id="1-recuperation-du-jeu-de-donnees-via-git">1. Récupération du Jeu de Données via Git</h2>
<p>Pour cette session d'annotation, le jeu de données a été préparé et mis à disposition dans un dépôt Git. La première étape consiste donc à le cloner sur votre machine locale.</p>
<p>Ouvrez un terminal et exécutez la commande suivante :</p>
<pre><code class="language-bash">git clone https://github.com/neutron-IT-organization/Data-Yolo-Test.git
</code></pre>
<p>Cette commande créera un nouveau dossier sur votre ordinateur, contenant l'ensemble des images prêtes à être importées dans CVAT.</p>
<p>Le jeu de données fourni a été conçu pour être représentatif et diversifié, afin de garantir la qualité des annotations et la future performance du modèle. Il inclut des images sous différents angles, éclairages, et avec des arrière-plans variés. Une fois le clonage terminé, vous disposerez du dossier nécessaire pour l'étape suivante.</p>
<h2 id="2-deploiement-et-configuration-de-cvat">2. Déploiement et Configuration de CVAT</h2>
<h3 id="21-deploiement-de-cvat-sur-openshift">2.1 Déploiement de CVAT sur OpenShift</h3>
<p>Avant de pouvoir annoter, nous devons déployer l'application CVAT sur notre cluster OpenShift.</p>
<h4 id="prerequis"><strong>Prérequis</strong></h4>
<p>Avant de commencer, assurez-vous de remplir les conditions suivantes :
1.  <strong>Installer <code>oc</code></strong> : L'outil de ligne de commande d'OpenShift doit être installé sur votre machine.
2.  <strong>Avoir les droits admin</strong> : Vous devez disposer de permissions d'administrateur sur le cluster pour créer un projet et les ressources associées.
3.  <strong>Être connecté au cluster</strong> : Assurez-vous d'être bien authentifié à votre cluster via la commande <code>oc login</code>.</p>
<h4 id="etapes-du-deploiement"><strong>Étapes du déploiement</strong></h4>
<p>Suivez ces étapes depuis votre terminal pour déployer CVAT :</p>
<ol>
<li><strong>Clonez le dépôt Git</strong> contenant les fichiers de configuration de CVAT.</li>
</ol>
<pre><code class="language-bash">git clone git@github.com:neutron-IT-organization/CVAT.git
</code></pre>
<ol>
<li><strong>Créez un nouveau projet</strong> (namespace) dédié à CVAT.</li>
</ol>
<pre><code class="language-bash">oc new-project cvat
</code></pre>
<ol>
<li><strong>Naviguez dans le dossier</strong> des manifestes de déploiement.</li>
</ol>
<pre><code class="language-bash">cd CVAT/manifest
</code></pre>
<ol>
<li><strong>Appliquez les configurations</strong>. 
Cette commande va créer toutes les ressources nécessaires (déploiements, services, volumes, etc.) pour faire fonctionner l'application.</li>
</ol>
<pre><code class="language-bash">oc apply -f .
</code></pre>
<ol>
<li>
<p><strong>Accédez à l'interface web</strong>. 
Une fois le déploiement terminé, allez dans la console web d'OpenShift, sélectionnez le projet <code>cvat</code>, puis naviguez dans la section <strong>Networking &gt; Routes</strong>. Cliquez sur l'URL générée pour ouvrir CVAT dans votre navigateur.</p>
</li>
<li>
<p><strong>Récupérez le mot de passe initial</strong>. Pour la première connexion, un compte super-utilisateur a été créé. Pour trouver son mot de passe :</p>
<ul>
<li>Dans le projet <code>cvat</code>, allez dans <strong>Secrets</strong>.</li>
<li>Cherchez et cliquez sur le secret nommé <strong><code>cvat-superuser</code></strong>.</li>
<li>Cliquez sur <strong>"Reveal Values"</strong> pour afficher le mot de passe. Le nom d'utilisateur est <code>admin</code>.</li>
</ul>
</li>
</ol>
<h3 id="22-creation-dune-organisation">2.2 Création d'une Organisation</h3>
<p>Pour travailler en équipe, la meilleure pratique est de créer une "Organisation". Cela permet de partager les projets et de gérer les permissions des différents membres.</p>
<ol>
<li>Depuis le tableau de bord, cliquez sur votre nom d'utilisateur en haut à droite, puis sur la flèche <code>&gt;</code> à côté de <strong>Organization</strong>.</li>
</ol>
<p><img alt="Accéder au menu Organisation" src="../img/Capture_CVAT_11.png" /></p>
<ol>
<li>
<p>Sur la page suivante, cliquez sur <strong><code>+ Create</code></strong> pour créer une nouvelle organisation.</p>
</li>
<li>
<p>Remplissez le formulaire en donnant un nom court (<em>Short name</em>) à votre organisation (ex: <code>orgTest</code>), puis cliquez sur <strong><code>Submit</code></strong>.
<img alt="Remplir le formulaire de création d'organisation" src="../img/Capture_CVAT_12.png" /></p>
</li>
<li>
<p>Une fois créée, vous basculez automatiquement dans le contexte de votre nouvelle organisation.
<img alt="Organisation créée et sélectionnée" src="../img/Capture_CVAT_13.png" /></p>
</li>
<li>
<p>Pour ajouter des collaborateurs, cliquez sur le bouton bleu <strong><code>Invite members</code></strong>.
<img alt="Inviter des membres à l'organisation" src="../img/Capture_CVAT_14.png" /></p>
</li>
<li>
<p>Dans la fenêtre qui s'ouvre :</p>
<ol>
<li>Entrez l'adresse e-mail de la personne à inviter.</li>
<li>Choisissez son rôle (<code>Worker</code>, <code>Supervisor</code>, etc.).</li>
<li>Cliquez sur <strong><code>OK</code></strong>.
<img alt="Fenêtre d'invitation des membres" src="../img/Capture_CVAT_15.png" /></li>
</ol>
</li>
</ol>
<h3 id="23-creation-du-projet-dannotation-sur-cvat">2.3 Création du Projet d'Annotation sur CVAT</h3>
<p>Une fois CVAT déployé et que vous êtes connecté, vous arriverez sur le tableau de bord. C'est ici que tous vos projets d'annotation seront listés. La première étape consiste à créer un nouveau projet pour nos images du Concorde.</p>
<p>Comme indiqué sur la capture d'écran, cliquez sur le bouton bleu <strong><code>+</code></strong> situé en haut à droite de l'interface, puis sélectionnez l'option <strong><code>+ Create a new project</code></strong>.</p>
<p><img alt="Création d'un projet sur CVAT" class="scaled-image" src="../img/Capture_CVAT_1.png" /></p>
<p>Vous serez alors redirigé vers la page de configuration du projet. Vous devez y définir deux éléments essentiels :</p>
<ol>
<li><strong>Name</strong> : Donnez un nom explicite à votre projet, par exemple "Aircraft Detection".</li>
<li><strong>Labels</strong> : C'est ici que vous déclarez les différentes classes d'objets que vous allez annoter. Pour ce guide, nous nous concentrons sur une seule classe. Cliquez sur <strong><code>Add label</code></strong> et tapez le nom <strong><code>Concorde</code></strong>.</li>
</ol>
<p>Une fois le nom et le label configurés comme sur l'image ci-dessous, cliquez sur le bouton <strong><code>Submit</code></strong> pour créer votre projet.</p>
<p><img alt="Configuration du projet et des labels" class="scaled-image" src="../img/Capture_CVAT_2.png" /></p>
<h2 id="3-creation-dune-tache-dannotation">3. Création d'une Tâche d'Annotation</h2>
<p>Dans CVAT, le travail d'annotation s'effectue au sein de <strong>tâches</strong> (<em>tasks</em>). Une tâche contient un lot d'images à annoter et les annotations qui lui sont associées. Un projet peut contenir plusieurs tâches, ce qui est pratique pour diviser le travail ou organiser différents lots de données.</p>
<p>Maintenant que notre projet est prêt, nous pouvons créer notre première tâche. Depuis la page du projet, qui est pour l'instant vide, cliquez sur le bouton <strong><code>+</code></strong> situé dans le coin inférieur droit pour commencer.</p>
<p><img alt="Création d'une tâche dans le projet CVAT" class="scaled-image" src="../img/Capture_CVAT_3.png" /> </p>
<p>Cette action ouvre la page "Create a new task". Ici, vous configurez la tâche et y ajoutez vos données.</p>
<ol>
<li><strong>Name</strong> : Donnez un nom à la tâche. C'est une bonne pratique de la nommer en fonction de son rôle dans le processus de Machine Learning, par exemple <strong><code>Train</code></strong>.</li>
<li><strong>Select files</strong> : C'est ici que vous importez les images préparées à la première étape. Assurez-vous d'être sur l'onglet <strong><code>My computer</code></strong>, puis cliquez sur la zone "Click or drag files to this area". Vous pouvez alors sélectionner plusieurs images ou directement le dossier complet qui les contient.</li>
</ol>
<p><img alt="Configuration de la tâche et ajout des fichiers." class="scaled-image" src="../img/Capture_CVAT_4.png" /> </p>
<p>Enfin, avant de soumettre, descendez jusqu'à la section <strong><code>Advanced configuration</code></strong>. Assurez-vous que l'option <strong><code>Choose format</code></strong> est bien sur <strong><code>CVAT for images 1.1</code></strong>.</p>
<p><img alt="Sélection du format d'importation." class="scaled-image" src="../img/Capture_CVAT_5.png" /> </p>
<p>Cliquez ensuite sur le bouton <strong><code>Submit</code></strong> en bas de la page pour finaliser la création de la tâche.</p>
<h2 id="4-lancement-de-lannotation">4. Lancement de l'Annotation</h2>
<p>Une fois la tâche créée et les images importées, nous sommes prêts à passer au cœur du travail : l'annotation.</p>
<p>Avant d'ouvrir l'éditeur, une bonne pratique consiste à spécifier à quel sous-ensemble de données cette tâche appartient. Dans le champ <strong><code>Subset</code></strong>, sélectionnez si ces images feront partie de votre jeu d'entraînement (<strong><code>Train</code></strong>), de test (<strong><code>Test</code></strong>), ou de validation (<strong><code>Validation</code></strong>). Cette métadonnée sera utile lors de l'exportation.</p>
<p>Ensuite, pour commencer à dessiner les boîtes englobantes, descendez à la section <strong><code>Jobs</code></strong>. Un "job" est l'unité de travail concrète. Cliquez sur le lien du job (par exemple, <strong><code>Job #...</code></strong>) pour ouvrir l'interface d'annotation.</p>
<p><img alt="Assignation du sous-ensemble et ouverture du job." class="scaled-image" src="../img/Capture_CVAT_6.png" /> </p>
<h3 id="linterface-dannotation">L'Interface d'Annotation</h3>
<p>Cette action ouvre l'éditeur principal. C'est ici que vous allez dessiner les boîtes englobantes sur chaque image. Le processus est simple et se déroule en plusieurs étapes, indiquées sur l'image ci-dessous :</p>
<p><img alt="Interface d'annotation de CVAT" class="scaled-image" src="../img/Capture_CVAT_7.png" /> </p>
<ol>
<li><strong>Sélectionner l'outil Rectangle</strong> : Dans la barre d'outils de gauche, cliquez sur l'icône <strong><code>Draw new rectangle</code></strong> pour activer l'outil de dessin.</li>
<li><strong>Choisir le bon Label</strong> : Juste en dessous, assurez-vous que le label sélectionné est bien celui que vous voulez annoter, ici <strong><code>Concorde</code></strong>.</li>
<li><strong>Confirmer la Forme</strong> : Vérifiez que la méthode de dessin est bien "Rectangle".</li>
<li><strong>Dessiner la Boîte</strong> : Sur l'image, cliquez et faites glisser votre souris pour dessiner une boîte qui entoure l'objet d'intérêt le plus précisément possible.</li>
<li><strong>Naviguer</strong> : Une fois l'objet annoté sur une image, utilisez les flèches en haut de l'écran pour passer à l'image suivante (<code>&gt;</code>) et répéter l'opération.</li>
</ol>
<p>Répétez ce processus pour toutes les images de votre tâche. Pensez à cliquer régulièrement sur l'icône de sauvegarde pour enregistrer votre travail. Une fois que vous avez terminé, vous pouvez simplement fermer l'onglet ou revenir à la page de la tâche ; votre travail est sauvegardé sur le serveur CVAT.</p>
<h2 id="5-exporter-les-annotations-au-format-yolo">5. Exporter les Annotations au Format YOLO</h2>
<p>Une fois que toutes les images ont été soigneusement annotées, il est temps d'exporter notre travail dans un format directement utilisable par YOLO.</p>
<p>Pour cela, retournez sur la page de la tâche et suivez ces deux étapes :</p>
<ol>
<li><strong>Valider le travail</strong> : Dans la liste des "Jobs", il est bon de changer l'état (<em>Stage</em>) à <strong><code>acceptance</code></strong>. Cela permet de marquer officiellement que le travail d'annotation pour ce lot est terminé et validé.</li>
<li><strong>Lancer l'exportation</strong> : En haut à droite de la page, cliquez sur le bouton <strong><code>Actions</code></strong>. Dans le menu qui apparaît, sélectionnez <strong><code>Export task dataset</code></strong>.</li>
</ol>
<p><img alt="Validation et exportation de la tâche." class="scaled-image" src="../img/Capture_CVAT_8.png" /> </p>
<p>Une fenêtre de dialogue s'ouvre alors. C'est ici que vous finalisez les options d'exportation :</p>
<ul>
<li><strong>Export format</strong> : Choisissez <strong><code>YOLO 1.1</code></strong> dans la liste. C'est essentiel pour obtenir des fichiers d'annotation compatibles.</li>
<li><strong>Save images</strong> : Cochez cette case pour inclure les images avec leurs fichiers d'annotation dans l'archive <code>.zip</code> qui sera générée.</li>
</ul>
<p>Une fois ces options configurées, cliquez sur <strong><code>OK</code></strong> pour lancer ltéléchargement du fichier.</p>
<p><img alt="Configuration de l'exportation au format YOLO." class="scaled-image" src="../img/Capture_CVAT_9.png" /></p>
<h2 id="6-preparation-et-centralisation-du-dataset-sur-minio">6. Préparation et Centralisation du Dataset sur MinIO</h2>
<p>Après avoir exporté vos archives <code>.zip</code> depuis CVAT pour chaque lot (train, test, validation), l'étape suivante consiste à organiser ces fichiers dans une structure de dossiers propre. Cette organisation est cruciale pour que le script d'entraînement puisse retrouver facilement les données.</p>
<p>Sur votre machine locale, créez un dossier principal qui contiendra l'ensemble de votre dataset (par exemple, <code>data_CVAT</code>). À l'intérieur de celui-ci, décompressez vos archives pour obtenir les sous-dossiers <code>test</code>, <code>train</code>, et <code>valid</code>. Chacun de ces dossiers doit contenir à la fois les images et leurs fichiers d'annotation <code>.txt</code> correspondants.</p>
<p>Votre structure de fichiers finale devrait ressembler à cet exemple :</p>
<p><img alt="Exemple de structure de dossier pour le dataset." src="../img/Capture_CVAT_10.png" /></p>
<p>Une fois que votre dataset est bien organisé, la dernière étape est de téléverser le dossier principal (<code>data_CVAT</code>) sur votre bucket MinIO. Cela permet de centraliser vos données et de les rendre accessibles pour votre environnement d'entraînement, comme un notebook sur OpenShift AI.</p>
<h2 id="7-importation-du-dataset-pour-lentrainement">7. Importation du Dataset pour l'Entraînement</h2>
<p>Maintenant que notre dataset est proprement organisé et centralisé sur MinIO, nous devons établir la connexion entre notre notebook et le serveur MinIO. Pour des raisons de sécurité, les identifiants (clés d'accès) ne sont jamais écrits directement dans le code. Sur OpenShift AI, la méthode recommandée est d'utiliser une "Connexion de données", qui stocke ces informations de manière sécurisée et les rend disponibles pour votre workbench.</p>
<h3 id="71-configuration-via-linterface-dopenshift-ai">7.1. Configuration via l'Interface d'OpenShift AI</h3>
<p>La connexion se fait en deux temps, directement dans l'interface graphique :</p>
<h4 id="711-creer-une-connexion-de-donnees">7.1.1. Créer une Connexion de Données :</h4>
<p>Dans votre projet sur OpenShift AI, allez dans la section "Connexions de données" et cliquez sur "Ajouter une connexion de données". Remplissez les champs avec les informations de votre serveur MinIO :</p>
<p>Nom de la connexion : Un nom descriptif (ex: Connexion MinIO Projet Yolo).</p>
<p>Access key ID : Votre clé d'accès MinIO.</p>
<p>Secret access key : Votre clé secrète MinIO.</p>
<p>Endpoint : L'URL de votre service MinIO.</p>
<p><img alt="Architecture RAG" class="scaled-image" src="../img/Capture_connections_1.png" /> 
<img alt="Architecture RAG" class="scaled-image" src="../img/Capture_connections_2.png" /> 
<img alt="Architecture RAG" class="scaled-image" src="../img/Capture_connections_3.png" /> </p>
<h4 id="712-lier-la-connexion-au-workbench">7.1.2. Lier la Connexion au Workbench :</h4>
<p>Lors de la configuration de votre workbench (ou en le modifiant), descendez jusqu'à la section "Connexions de données". Sélectionnez dans la liste déroulante la connexion que vous venez de créer.</p>
<p><img alt="Architecture RAG" class="scaled-image" src="../img/Capture_connections_4.png" /> 
<img alt="Architecture RAG" class="scaled-image" src="../img/Capture_connections_5.png" /> 
<img alt="Architecture RAG" class="scaled-image" src="../img/Capture_connections_6.png" /> </p>
<p>En faisant cela, OpenShift AI va automatiquement injecter les identifiants de cette connexion comme variables d'environnement (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_S3_ENDPOINT) dans l'environnement de votre notebook.</p>
<p>Maintenant, nous allons utiliser un script Python dans notre environnement d'entraînement pour simplement télécharger ce dataset depuis MinIO et le rendre disponible localement pour l'entraînement.</p>
<h3 id="72-configuration-et-connexion">7.2. Configuration et Connexion</h3>
<p>La première partie du script consiste à définir les chemins et à établir une connexion sécurisée avec notre serveur MinIO en utilisant les variables d'environnement.</p>
<pre><code class="language-python">import os
import boto3
import shutil
import yaml

# Configuration des chemins et du client MinIO
OUTPUT_DATASET_PATH = &quot;concorde_yolo_dataset&quot;
S3_SOURCE_PREFIX = &quot;data_CVAT&quot; # Le dossier téléversé à l'étape précédente

# Connexion sécurisée au client S3
client = boto3.client(
    &quot;s3&quot;,
    endpoint_url=os.environ.get(&quot;AWS_S3_ENDPOINT&quot;),
    aws_access_key_id=os.environ.get(&quot;AWS_ACCESS_KEY_ID&quot;),
    aws_secret_access_key=os.environ.get(&quot;AWS_SECRET_ACCESS_KEY&quot;)
)
</code></pre>
<h3 id="73-telechargement-et-restructuration">7.3. Téléchargement et Restructuration</h3>
<p>La fonction principale du script parcourt les dossiers <code>train</code>, <code>test</code> et <code>valid</code> sur MinIO. Pour chaque fichier, elle le télécharge et le place dans la structure de dossiers requise par YOLO (<code>images/</code> et <code>labels/</code>).</p>
<pre><code class="language-python">def download_and_restructure_s3_folder(bucket, s3_prefix, local_base_path):
    &quot;&quot;&quot;
    Télécharge et restructure un dossier depuis S3 (MinIO) vers la structure YOLO.
    &quot;&quot;&quot;
    with ThreadPoolExecutor(max_workers=10) as executor:
        paginator = client.get_paginator('list_objects_v2')
        pages = paginator.paginate(Bucket=bucket, Prefix=s3_prefix)

        all_objects = [obj for page in pages for obj in page.get('Contents', [])]

        if not all_objects:
            print(f&quot;Aucun objet trouvé dans {bucket}/{s3_prefix}. Le script va s'arrêter.&quot;)
            return

        with tqdm(total=len(all_objects), desc=&quot;Traitement des fichiers&quot;, unit=&quot;file&quot;) as pbar:
            futures = []
            for obj in all_objects:
                key = obj['Key']
                if key.endswith('/'):
                    pbar.update(1)
                    continue

                file_extension = os.path.splitext(key)[1].lower()
                is_image = file_extension in ['.jpg', '.jpeg', '.png']
                is_label = file_extension == '.txt'

                if not is_image and not is_label:
                    pbar.update(1)
                    continue

                try:
                    split_type = key.replace(s3_prefix, '').strip('/').split('/')[0]
                    if split_type == 'valid':
                        split_type = 'valid'
                except IndexError:
                    continue

                subfolder = 'images' if is_image else 'labels'
                file_name = os.path.basename(key)
                local_file_path = os.path.join(local_base_path, split_type, subfolder, file_name)

                os.makedirs(os.path.dirname(local_file_path), exist_ok=True)

                future = executor.submit(client.download_file, bucket, key, local_file_path)
                future.add_done_callback(lambda p: pbar.update(1))
                futures.append(future)

            for future in futures:
                future.result()
</code></pre>
<h3 id="74-creation-du-fichier-datayaml">7.4. Création du Fichier data.yaml</h3>
<p>Une fois les données structurées, une fonction génère le fichier <code>data.yaml</code>. Ce fichier est indispensable pour YOLO : il lui indique où trouver les différents ensembles de données et quelles sont les classes à apprendre.</p>
<pre><code class="language-python">def create_yaml_file(output_path):
    yaml_content = {
        'train': os.path.abspath(os.path.join(output_path, 'train', 'images')),
        'val': os.path.abspath(os.path.join(output_path, 'valid', 'images')),
        'test': os.path.abspath(os.path.join(output_path, 'test', 'images')),
        'nc': 1,
        'names': ['Concorde']
    }

    yaml_file_path = os.path.join(output_path, 'data.yaml')
    with open(yaml_file_path, 'w') as f:
        yaml.dump(yaml_content, f, sort_keys=False)
</code></pre>
<h3 id="75-execution">7.5. Exécution</h3>
<p>Enfin, le script principal orchestre ces étapes : il nettoie l'environnement, lance le téléchargement et la restructuration, puis crée le fichier <code>data.yaml</code>, rendant le dataset prêt pour l'entraînement.</p>
<pre><code class="language-python"># --- 5. Script principal ---
if __name__ == &quot;__main__&quot;:
    if os.path.exists(OUTPUT_DATASET_PATH):
        print(f&quot;Nettoyage du répertoire existant : {OUTPUT_DATASET_PATH}&quot;)
        shutil.rmtree(OUTPUT_DATASET_PATH)

    print(f&quot;Début du téléchargement et de la restructuration depuis '{S3_SOURCE_PREFIX}'...&quot;)
    download_and_restructure_s3_folder(AWS_S3_BUCKET, S3_SOURCE_PREFIX, OUTPUT_DATASET_PATH)

    create_yaml_file(OUTPUT_DATASET_PATH)

    print(&quot;\n Processus terminé. Votre dataset est prêt dans le dossier :&quot;, OUTPUT_DATASET_PATH)
</code></pre>
<h2 id="8-entrainement-du-modele-avec-yolo">8. Entraînement du Modèle avec YOLO</h2>
<p>Maintenant que notre dataset est importé, structuré et prêt à l'emploi avec son fichier <code>data.yaml</code>, nous pouvons passer à l'étape la plus excitante : l'entraînement de notre modèle de détection d'objets. Le processus utilisera le transfer learning, une technique qui consiste à partir d'un modèle déjà pré-entraîné pour l'adapter à notre besoin spécifique, ce qui est plus rapide et efficace.</p>
<h3 id="81-preparation-du-modele-de-base-yolo">8.1. Préparation du Modèle de Base YOLO</h3>
<p>Pour le transfer learning, notre point de départ est un modèle pré-entraîné, généreusement mis à disposition par l'équipe Ultralytics. Nous allons le télécharger directement depuis leur dépôt GitHub.</p>
<p><strong>Accéder au Dépôt GitHub</strong></p>
<p>Rendez-vous sur la page officielle du projet en cliquant sur ce lien : <a href="https://github.com/ultralytics/ultralytics/tree/main?tab=readme-ov-file">https://github.com/ultralytics/ultralytics/tree/main?tab=readme-ov-file</a>.</p>
<p><strong>Trouver le Tableau des Modèles</strong></p>
<p>Sur la page principale, faites défiler vers le bas jusqu'à la section du <code>README</code> qui présente les différents modèles disponibles. Vous y trouverez un tableau intitulé <strong>"Detection (COCO)"</strong>, comme celui ci-dessous. Ce tableau liste les différentes variantes du modèle, leurs performances et leurs tailles.</p>
<p><img alt="Tableau des modèles YOLO sur GitHub" class="scaled-image" src="../img/Capture_Version_Yolo.png" /> </p>
<p><strong>Télécharger le Modèle</strong></p>
<p>Chaque nom dans la colonne <strong>"Model"</strong> est un lien de téléchargement direct. Pour notre guide, nous allons utiliser la version "nano", qui est légère et rapide, idéale pour commencer.</p>
<p><strong>Repérez la ligne <code>YOLOv11n</code> et cliquez dessus</strong> </p>
<p>Le téléchargement du fichier <code>yolov11n.pt</code> démarrera automatiquement.</p>
<p>Une fois que vous avez ce fichier sur votre ordinateur, l'étape suivante consiste à le téléverser dans votre bucket MinIO, où il sera accessible pour notre script d'entraînement.</p>
<h3 id="82-installation-et-configuration">8.2. Installation et Configuration</h3>
<p>La première étape dans notre notebook d'entraînement est d'installer la librairie <code>ultralytics</code> qui contient l'implémentation de YOLO, puis de définir nos configurations.</p>
<pre><code class="language-python"># 1. Installation de la librairie Ultralytics
!pip install ultralytics

# 2. Import des librairies nécessaires
from ultralytics import YOLO
import os

# 3. Configuration des hyperparamètres de l'entraînement
EPOCHS = 100
IMGSZ = 640
NB_FROZEN_LAYER = 10 # Nombre de couches du modèle à &quot;geler&quot; (ne pas ré-entraîner)

# 4. Définition des chemins importants
DATA_CONFIG_PATH = './concorde_yolo_dataset/data.yaml'
BASE_MODEL_PATH = &quot;yolov11n.pt&quot; # Modèle pré-entraîné qui servira de base
</code></pre>
<p>Ici, nous définissons des paramètres clés comme le nombre d'époques (cycles d'entraînement), la taille des images, et le nombre de couches du modèle que nous allons "geler". Geler des couches signifie qu'elles ne seront pas modifiées pendant l'entraînement, conservant ainsi les connaissances générales acquises lors de leur pré-entraînement.</p>
<h3 id="83-chargement-du-modele-de-base">8.3. Chargement du Modèle de Base</h3>
<p>Nous n'entraînons pas un modèle à partir de zéro. Nous téléchargeons un modèle YOLOv11 pré-entraîné (<code>yolov11n.pt</code>) depuis notre stockage MinIO. Ce modèle sait déjà reconnaître des formes et des textures générales, nous n'avons plus qu'à lui apprendre à reconnaître spécifiquement le "Concorde".</p>
<pre><code class="language-python"># Connexion au client S3...
# ...
# Téléchargement du modèle de base depuis MinIO
client.download_file(AWS_S3_BUCKET, BASE_MODEL_PATH, &quot;yolov11n.pt&quot;)
</code></pre>
<h3 id="84-lancement-de-lentrainement">8.4. Lancement de l'Entraînement</h3>
<p>Avec le modèle de base et le dataset prêts, une seule ligne de code suffit pour lancer l'entraînement.</p>
<pre><code class="language-python"># Charger le modèle pré-entraîné
model = YOLO('yolov11n.pt')

# Lancer l'entraînement
results = model.train(
    data=DATA_CONFIG_PATH, 
    epochs=EPOCHS, 
    imgsz=IMGSZ, 
    freeze=NB_FROZEN_LAYER,
    batch=-1 # -1 pour un ajustement automatique du batch size
)
</code></pre>
<p>YOLO s'occupe de tout : il charge les données, augmente le dataset (data augmentation), entraîne le modèle pendant 100 époques, et sauvegarde les résultats, y compris les "poids" du meilleur modèle obtenu.</p>
<h3 id="85-exportation-et-sauvegarde-des-resultats">8.5. Exportation et Sauvegarde des Résultats</h3>
<p>Une fois l'entraînement terminé, la bonne pratique est d'exporter le modèle au format <strong>ONNX</strong>. C'est un format standard qui facilite le déploiement sur différentes plateformes.</p>
<p>Ensuite, nous téléversons les résultats importants sur <strong>MinIO</strong> pour les conserver et les utiliser plus tard :</p>
<ul>
<li>Le meilleur modèle au format <code>.pt</code> (natif PyTorch).</li>
<li>Le modèle exporté au format <code>.onnx</code>.</li>
<li>Le fichier <code>results.csv</code> qui contient les métriques de performance de l'entraînement.</li>
</ul>
<pre><code class="language-python"># Charger les meilleurs poids obtenus après l'entraînement
model = YOLO('runs/detect/train/weights/best.pt')

# Exporter au format ONNX
model.export(format=&quot;onnx&quot;)

# Téléverser les modèles et les résultats sur MinIO
client.upload_file('runs/detect/train/weights/best.onnx', ...)
client.upload_file('runs/detect/train/weights/best.pt', ...)
client.upload_file('runs/detect/train/results.csv', ...)
</code></pre>
<h2 id="9-comparaison-et-validation-des-resultats">9. Comparaison et Validation des Résultats</h2>
<p>Après avoir entraîné notre modèle, l'étape finale est de vérifier qu'il est bien meilleur que le modèle de base pour notre tâche spécifique. Nous allons effectuer une comparaison à la fois quantitative (avec des métriques de performance) et qualitative (en visualisant les détections).</p>
<h3 id="91-comparaison-quantitative-mesurer-la-performance">9.1. Comparaison Quantitative : Mesurer la Performance</h3>
<p>La première méthode est de mesurer la performance de chaque modèle sur notre jeu de test à l'aide de la fonction <code>.val()</code>. Cette fonction calcule des métriques standards comme la mAP (mean Average Precision), qui est un excellent indicateur de la précision d'un modèle de détection.</p>
<p>Le script charge les deux modèles (le modèle de base et notre nouveau modèle) puis exécute la validation sur les deux.</p>
<pre><code class="language-python">from ultralytics import YOLO

# Charger les deux modèles
model_base = YOLO(&quot;/tmp/base-model.pt&quot;) # Le modèle YOLOv11n original
model_new = YOLO(&quot;/tmp/new-model.pt&quot;)  # Notre modèle fine-tuné

# Lancer la validation pour chaque modèle sur le même jeu de test
print(&quot;Validation du modèle de base :&quot;)
results_base = model_base.val(data=&quot;concorde_yolo_dataset/data.yaml&quot;)

print(&quot;\\nValidation de notre nouveau modèle :&quot;)
results_new = model_new.val(data=&quot;concorde_yolo_dataset/data.yaml&quot;)
</code></pre>
<p>L'objectif est de constater que la mAP pour la classe "Concorde" est très faible (voire nulle) pour le modèle de base, et significativement plus élevée pour notre modèle spécialisé.</p>
<h3 id="92-comparaison-qualitative-visualiser-la-detection">9.2. Comparaison Qualitative : Visualiser la Détection</h3>
<p>Les chiffres sont importants, mais une inspection visuelle est souvent plus parlante. Le script suivant sélectionne aléatoirement 5 images de notre jeu de test et lance la détection avec les deux modèles pour chacune d'entre elles.</p>
<pre><code class="language-python">import random

# Sélectionner 5 images de test au hasard
image_filenames = os.listdir(&quot;concorde_yolo_dataset/test/images&quot;)
random_images = random.sample(image_filenames, 5)

# Pour chaque image, afficher la détection des deux modèles
for image_file in random_images:
    test_image_path = os.path.join(&quot;concorde_yolo_dataset/test/images&quot;, image_file)

    # Inférence avec le modèle de base
    print(f&quot;\\n--- Détection avec le modèle DE BASE sur {image_file} ---&quot;)
    res_base = model_base(test_image_path)
    res_base[0].show()

    # Inférence avec notre nouveau modèle
    print(f&quot;--- Détection avec notre NOUVEAU modèle sur {image_file} ---&quot;)
    res_new = model_new(test_image_path)
    res_new[0].show()
</code></pre>
<p>Le résultat attendu est clair : le modèle de base détectera l'avion mais avec une étiquette générique ("airplane"), tandis que notre modèle dessinera une boîte précise avec le label correct "Concorde", prouvant ainsi le succès de notre spécialisation.</p>
<p><img alt="Comparaison de détection sur un Concorde" class="scaled-image" src="../img/Capture_Resultat_YOLO.png" /> </p>
<p>Il est également important de noter le comportement du modèle face à des avions qui ne sont pas des Concordes. Comme notre entraînement s'est focalisé exclusivement sur la classe "Concorde", le modèle a appris à ignorer les autres types d'avion, comme le montre l'exemple ci-dessous. C'est la preuve de sa spécialisation : il ne se contente pas de trouver des avions, il trouve <strong>uniquement</strong> des Concordes.</p>
<p><img alt="Test sur un avion non-Concorde" class="scaled-image" src="../img/Capture_Resultat_YOLO_1.png" /> </p>
<hr />
<h2 id="conclusion-generale">Conclusion Générale</h2>
<p>À travers ce guide, nous avons parcouru l'ensemble du cycle de vie d'un projet de vision par ordinateur : de la collecte d'images à l'annotation précise avec CVAT, en passant par la structuration des données et l'entraînement d'un modèle YOLO sur OpenShift. Vous avez pu constater comment le transfer learning permet, avec un jeu de données relativement modeste, de spécialiser un modèle puissant pour une tâche de détection personnalisée.</p>
<p>La clé du succès réside dans la qualité des données annotées et une méthodologie structurée. Vous êtes maintenant prêt à appliquer ces étapes à vos propres projets pour détecter n'importe quel objet !</p>
<hr />
<p><strong>Auteur : <a href="https://www.linkedin.com/in/mohamed-reda-bouamoud-1297a3248/">Mohamed-Reda BOUAMOUD</a></strong></p>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Retour en haut de la page
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - 2025 Neutron IT
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://neutron-it.fr" target="_blank" rel="noopener" title="neutron-it.fr" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M351.9 280H161c2.9 64.5 17.2 123.9 37.5 167.4 11.4 24.5 23.7 41.8 35.1 52.4 11.2 10.5 18.9 12.2 22.9 12.2s11.7-1.7 22.9-12.2c11.4-10.6 23.7-28 35.1-52.4 20.3-43.5 34.6-102.9 37.5-167.4zm-191-48h190.9c-2.8-64.5-17.1-123.9-37.4-167.4-11.4-24.4-23.7-41.8-35.1-52.4C268.1 1.7 260.4 0 256.4 0s-11.7 1.7-22.9 12.2c-11.4 10.6-23.7 28-35.1 52.4-20.3 43.5-34.6 102.9-37.5 167.4m-48 0c3.5-85.6 25.6-165.1 57.9-217.3C78.7 47.3 10.9 131.2 1.5 232zM1.5 280c9.4 100.8 77.2 184.7 169.3 217.3-32.3-52.2-54.4-131.7-57.9-217.3zm398.4 0c-3.5 85.6-25.6 165.1-57.9 217.3 92.1-32.7 159.9-116.5 169.3-217.3zm111.4-48C501.9 131.2 434.1 47.3 342 14.7c32.3 52.2 54.4 131.7 57.9 217.3z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/neutron-IT-organization" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://quay.io/neutron-it" target="_blank" rel="noopener" title="quay.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/company/neutron-it" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.indexes", "navigation.sections", "navigation.top", "search.suggest", "search.highlight", "search.share", "toc.follow"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copi\u00e9 dans le presse-papier", "clipboard.copy": "Copier dans le presse-papier", "search.result.more.one": "1 de plus sur cette page", "search.result.more.other": "# de plus sur cette page", "search.result.none": "Aucun document trouv\u00e9", "search.result.one": "1 document trouv\u00e9", "search.result.other": "# documents trouv\u00e9s", "search.result.placeholder": "Taper pour d\u00e9marrer la recherche", "search.result.term.missing": "Non trouv\u00e9", "select.version": "S\u00e9lectionner la version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>